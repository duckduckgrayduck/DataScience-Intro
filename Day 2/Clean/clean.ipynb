{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873b8683-0cec-4108-84eb-c250ef7e5ae1",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "This notebook is to follow along the Pythonic Data Cleaning with Pandas and NumPy here: \n",
    "https://realpython.com/python-data-cleaning-numpy-pandas/\n",
    "\n",
    "I've included all of the datasets in the GitHub Repo where you will also find this activity. \n",
    "\n",
    "We’ll cover the following:\n",
    "\n",
    "    - Dropping unnecessary columns in a DataFrame\n",
    "    - Changing the index of a DataFrame\n",
    "    - Using .str() methods to clean columns\n",
    "    - Using the DataFrame.applymap() function to clean the entire dataset, element-wise\n",
    "    - Renaming columns to a more recognizable set of labels\n",
    "    - Skipping unnecessary rows in a CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab79ea80-b738-423e-84a3-86ab30ee601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "52246dbe-7875-4a4c-b6b8-d9e56489b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BL-Flickr-Images-Book.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "abb10680-8279-4c8b-95b9-4e94a9603567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>Edition Statement</th>\n",
       "      <th>Place of Publication</th>\n",
       "      <th>Date of Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Contributors</th>\n",
       "      <th>Corporate Author</th>\n",
       "      <th>Corporate Contributors</th>\n",
       "      <th>Former owner</th>\n",
       "      <th>Engraver</th>\n",
       "      <th>Issuance type</th>\n",
       "      <th>Flickr URL</th>\n",
       "      <th>Shelfmarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>1879 [1878]</td>\n",
       "      <td>S. Tinsley &amp; Co.</td>\n",
       "      <td>Walter Forbes. [A novel.] By A. A</td>\n",
       "      <td>A. A.</td>\n",
       "      <td>FORBES, Walter.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>monographic</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "      <td>British Library HMNTS 12641.b.30.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London; Virtue &amp; Yorston</td>\n",
       "      <td>1868</td>\n",
       "      <td>Virtue &amp; Co.</td>\n",
       "      <td>All for Greed. [A novel. The dedication signed...</td>\n",
       "      <td>A., A. A.</td>\n",
       "      <td>BLAZE DE BURY, Marie Pauline Rose - Baroness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>monographic</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "      <td>British Library HMNTS 12626.cc.2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>1869</td>\n",
       "      <td>Bradbury, Evans &amp; Co.</td>\n",
       "      <td>Love the Avenger. By the author of “All for Gr...</td>\n",
       "      <td>A., A. A.</td>\n",
       "      <td>BLAZE DE BURY, Marie Pauline Rose - Baroness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>monographic</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "      <td>British Library HMNTS 12625.dd.1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>1851</td>\n",
       "      <td>James Darling</td>\n",
       "      <td>Welsh Sketches, chiefly ecclesiastical, to the...</td>\n",
       "      <td>A., E. S.</td>\n",
       "      <td>Appleyard, Ernest Silvanus.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>monographic</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "      <td>British Library HMNTS 10369.bbb.15.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>480</td>\n",
       "      <td>A new edition, revised, etc.</td>\n",
       "      <td>London</td>\n",
       "      <td>1857</td>\n",
       "      <td>Wertheim &amp; Macintosh</td>\n",
       "      <td>[The World in which I live, and my place in it...</td>\n",
       "      <td>A., E. S.</td>\n",
       "      <td>BROOME, John Henry.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>monographic</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "      <td>British Library HMNTS 9007.d.28.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Identifier             Edition Statement      Place of Publication  \\\n",
       "0         206                           NaN                    London   \n",
       "1         216                           NaN  London; Virtue & Yorston   \n",
       "2         218                           NaN                    London   \n",
       "3         472                           NaN                    London   \n",
       "4         480  A new edition, revised, etc.                    London   \n",
       "\n",
       "  Date of Publication              Publisher  \\\n",
       "0         1879 [1878]       S. Tinsley & Co.   \n",
       "1                1868           Virtue & Co.   \n",
       "2                1869  Bradbury, Evans & Co.   \n",
       "3                1851          James Darling   \n",
       "4                1857   Wertheim & Macintosh   \n",
       "\n",
       "                                               Title     Author  \\\n",
       "0                  Walter Forbes. [A novel.] By A. A      A. A.   \n",
       "1  All for Greed. [A novel. The dedication signed...  A., A. A.   \n",
       "2  Love the Avenger. By the author of “All for Gr...  A., A. A.   \n",
       "3  Welsh Sketches, chiefly ecclesiastical, to the...  A., E. S.   \n",
       "4  [The World in which I live, and my place in it...  A., E. S.   \n",
       "\n",
       "                                   Contributors  Corporate Author  \\\n",
       "0                               FORBES, Walter.               NaN   \n",
       "1  BLAZE DE BURY, Marie Pauline Rose - Baroness               NaN   \n",
       "2  BLAZE DE BURY, Marie Pauline Rose - Baroness               NaN   \n",
       "3                   Appleyard, Ernest Silvanus.               NaN   \n",
       "4                           BROOME, John Henry.               NaN   \n",
       "\n",
       "   Corporate Contributors Former owner  Engraver Issuance type  \\\n",
       "0                     NaN          NaN       NaN   monographic   \n",
       "1                     NaN          NaN       NaN   monographic   \n",
       "2                     NaN          NaN       NaN   monographic   \n",
       "3                     NaN          NaN       NaN   monographic   \n",
       "4                     NaN          NaN       NaN   monographic   \n",
       "\n",
       "                                          Flickr URL  \\\n",
       "0  http://www.flickr.com/photos/britishlibrary/ta...   \n",
       "1  http://www.flickr.com/photos/britishlibrary/ta...   \n",
       "2  http://www.flickr.com/photos/britishlibrary/ta...   \n",
       "3  http://www.flickr.com/photos/britishlibrary/ta...   \n",
       "4  http://www.flickr.com/photos/britishlibrary/ta...   \n",
       "\n",
       "                            Shelfmarks  \n",
       "0    British Library HMNTS 12641.b.30.  \n",
       "1    British Library HMNTS 12626.cc.2.  \n",
       "2    British Library HMNTS 12625.dd.1.  \n",
       "3  British Library HMNTS 10369.bbb.15.  \n",
       "4     British Library HMNTS 9007.d.28.  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52177f74-057f-43a2-a80d-a68ae52cc41c",
   "metadata": {},
   "source": [
    "## Dropping Columns in a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32876eb8-165e-43d0-ba2b-8b5f02c1b90e",
   "metadata": {},
   "source": [
    "When we look at the first five entries using the [head()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html) method, we can see that a handful of columns provide information that would be helpful to the library but isn’t very descriptive of the books themselves: Edition Statement, Corporate Author, Corporate Contributors, Former owner, Engraver, Issuance type and Shelfmarks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c995f357-641d-4f5d-ab61-f15874759198",
   "metadata": {},
   "source": [
    "We can drop these columns from the dataframe using [drop()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f045a09e-f69e-43b1-8880-4233befaf990",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> to_drop = ['Edition Statement',\n",
    "...            'Corporate Author',\n",
    "...            'Corporate Contributors',\n",
    "...            'Former owner',\n",
    "...            'Engraver',\n",
    "...            'Contributors',\n",
    "...            'Issuance type',\n",
    "...            'Shelfmarks']\n",
    "\n",
    ">>> df.drop(to_drop, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008d8ce7-8d1e-4ddb-b415-467917960cfa",
   "metadata": {},
   "source": [
    "We can verify that our drops worked by again printing head. Or if we desire to see the last entries we can use [tail()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html) instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "53b2bae6-2280-49ac-8d48-4ed4d6ffc8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>Place of Publication</th>\n",
       "      <th>Date of Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Flickr URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206</td>\n",
       "      <td>London</td>\n",
       "      <td>1879 [1878]</td>\n",
       "      <td>S. Tinsley &amp; Co.</td>\n",
       "      <td>Walter Forbes. [A novel.] By A. A</td>\n",
       "      <td>A. A.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216</td>\n",
       "      <td>London; Virtue &amp; Yorston</td>\n",
       "      <td>1868</td>\n",
       "      <td>Virtue &amp; Co.</td>\n",
       "      <td>All for Greed. [A novel. The dedication signed...</td>\n",
       "      <td>A., A. A.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218</td>\n",
       "      <td>London</td>\n",
       "      <td>1869</td>\n",
       "      <td>Bradbury, Evans &amp; Co.</td>\n",
       "      <td>Love the Avenger. By the author of “All for Gr...</td>\n",
       "      <td>A., A. A.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>472</td>\n",
       "      <td>London</td>\n",
       "      <td>1851</td>\n",
       "      <td>James Darling</td>\n",
       "      <td>Welsh Sketches, chiefly ecclesiastical, to the...</td>\n",
       "      <td>A., E. S.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>480</td>\n",
       "      <td>London</td>\n",
       "      <td>1857</td>\n",
       "      <td>Wertheim &amp; Macintosh</td>\n",
       "      <td>[The World in which I live, and my place in it...</td>\n",
       "      <td>A., E. S.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Identifier      Place of Publication Date of Publication  \\\n",
       "0         206                    London         1879 [1878]   \n",
       "1         216  London; Virtue & Yorston                1868   \n",
       "2         218                    London                1869   \n",
       "3         472                    London                1851   \n",
       "4         480                    London                1857   \n",
       "\n",
       "               Publisher                                              Title  \\\n",
       "0       S. Tinsley & Co.                  Walter Forbes. [A novel.] By A. A   \n",
       "1           Virtue & Co.  All for Greed. [A novel. The dedication signed...   \n",
       "2  Bradbury, Evans & Co.  Love the Avenger. By the author of “All for Gr...   \n",
       "3          James Darling  Welsh Sketches, chiefly ecclesiastical, to the...   \n",
       "4   Wertheim & Macintosh  [The World in which I live, and my place in it...   \n",
       "\n",
       "      Author                                         Flickr URL  \n",
       "0      A. A.  http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "1  A., A. A.  http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "2  A., A. A.  http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "3  A., E. S.  http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "4  A., E. S.  http://www.flickr.com/photos/britishlibrary/ta...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1e0085b9-a1bd-42ac-8524-0ccf0be5fea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>Place of Publication</th>\n",
       "      <th>Date of Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Flickr URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8282</th>\n",
       "      <td>4158088</td>\n",
       "      <td>London</td>\n",
       "      <td>1838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Parochial History of Cornwall, founded on,...</td>\n",
       "      <td>GIDDY, afterwards GILBERT, Davies.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8283</th>\n",
       "      <td>4158128</td>\n",
       "      <td>Derby</td>\n",
       "      <td>1831, 32</td>\n",
       "      <td>M. Mozley &amp; Son</td>\n",
       "      <td>The History and Gazetteer of the County of Der...</td>\n",
       "      <td>GLOVER, Stephen - of Derby</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8284</th>\n",
       "      <td>4159563</td>\n",
       "      <td>London</td>\n",
       "      <td>[1806]-22</td>\n",
       "      <td>T. Cadell and W. Davies</td>\n",
       "      <td>Magna Britannia; being a concise topographical...</td>\n",
       "      <td>LYSONS, Daniel - M.A., F.R.S., and LYSONS (Sam...</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8285</th>\n",
       "      <td>4159587</td>\n",
       "      <td>Newcastle upon Tyne</td>\n",
       "      <td>1834</td>\n",
       "      <td>Mackenzie &amp; Dent</td>\n",
       "      <td>An historical, topographical and descriptive v...</td>\n",
       "      <td>Mackenzie, E. (Eneas)</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8286</th>\n",
       "      <td>4160339</td>\n",
       "      <td>London</td>\n",
       "      <td>1834-43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Collectanea Topographica et Genealogica. [Firs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Identifier Place of Publication Date of Publication  \\\n",
       "8282     4158088               London                1838   \n",
       "8283     4158128                Derby            1831, 32   \n",
       "8284     4159563               London           [1806]-22   \n",
       "8285     4159587  Newcastle upon Tyne                1834   \n",
       "8286     4160339               London             1834-43   \n",
       "\n",
       "                    Publisher  \\\n",
       "8282                      NaN   \n",
       "8283          M. Mozley & Son   \n",
       "8284  T. Cadell and W. Davies   \n",
       "8285         Mackenzie & Dent   \n",
       "8286                      NaN   \n",
       "\n",
       "                                                  Title  \\\n",
       "8282  The Parochial History of Cornwall, founded on,...   \n",
       "8283  The History and Gazetteer of the County of Der...   \n",
       "8284  Magna Britannia; being a concise topographical...   \n",
       "8285  An historical, topographical and descriptive v...   \n",
       "8286  Collectanea Topographica et Genealogica. [Firs...   \n",
       "\n",
       "                                                 Author  \\\n",
       "8282                 GIDDY, afterwards GILBERT, Davies.   \n",
       "8283                         GLOVER, Stephen - of Derby   \n",
       "8284  LYSONS, Daniel - M.A., F.R.S., and LYSONS (Sam...   \n",
       "8285                              Mackenzie, E. (Eneas)   \n",
       "8286                                                NaN   \n",
       "\n",
       "                                             Flickr URL  \n",
       "8282  http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "8283  http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "8284  http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "8285  http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "8286  http://www.flickr.com/photos/britishlibrary/ta...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18735dca-44d9-40e1-8d17-18a26e910c28",
   "metadata": {},
   "source": [
    "Here we dropped the columns along axis = 1, meaning we dropped columns. <br>\n",
    "``` df.drop(to_drop, inplace=True, axis=1)```\n",
    "\n",
    "We could  alternatively call drop() directly with columns, and pass in our list of columns to drop. \n",
    "This is perhaps even more readable. <br>\n",
    "``` df.drop(columns=to_drop, inplace=True)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac11cfa0-659d-46fd-81f2-930c249ee3cc",
   "metadata": {},
   "source": [
    "## Changing the Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c32529d-5d36-427b-bf8c-de4d738d39c5",
   "metadata": {},
   "source": [
    "An index allows you to uniquely identify a row in a dataframe. Think of it as an ID or identifier for that row. An index should be something unique, so that when you use it to identify a row, you don't get conflicts. We notice that in our dataframe above, there is an identifier column. We can test to see if all of the values in that column are unique using [is_unique()](https://pandas.pydata.org/docs/reference/api/pandas.Series.is_unique.html) to see if it is a good candidate for being an index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3e012e1e-0b1b-4d56-a4de-431231beb33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> df['Identifier'].is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da3c1cc-d31d-46e6-82cd-c45ff244ca6a",
   "metadata": {},
   "source": [
    "Since it is unique, we can then assign the identifier colun to be the index using [set_index()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a8f106ec-7ee5-4f89-bbf2-ae2f86d51f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place of Publication</th>\n",
       "      <th>Date of Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Flickr URL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>London</td>\n",
       "      <td>1879 [1878]</td>\n",
       "      <td>S. Tinsley &amp; Co.</td>\n",
       "      <td>Walter Forbes. [A novel.] By A. A</td>\n",
       "      <td>A. A.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>London; Virtue &amp; Yorston</td>\n",
       "      <td>1868</td>\n",
       "      <td>Virtue &amp; Co.</td>\n",
       "      <td>All for Greed. [A novel. The dedication signed...</td>\n",
       "      <td>A., A. A.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>London</td>\n",
       "      <td>1869</td>\n",
       "      <td>Bradbury, Evans &amp; Co.</td>\n",
       "      <td>Love the Avenger. By the author of “All for Gr...</td>\n",
       "      <td>A., A. A.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>London</td>\n",
       "      <td>1851</td>\n",
       "      <td>James Darling</td>\n",
       "      <td>Welsh Sketches, chiefly ecclesiastical, to the...</td>\n",
       "      <td>A., E. S.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>London</td>\n",
       "      <td>1857</td>\n",
       "      <td>Wertheim &amp; Macintosh</td>\n",
       "      <td>[The World in which I live, and my place in it...</td>\n",
       "      <td>A., E. S.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Place of Publication Date of Publication  \\\n",
       "Identifier                                                 \n",
       "206                           London         1879 [1878]   \n",
       "216         London; Virtue & Yorston                1868   \n",
       "218                           London                1869   \n",
       "472                           London                1851   \n",
       "480                           London                1857   \n",
       "\n",
       "                        Publisher  \\\n",
       "Identifier                          \n",
       "206              S. Tinsley & Co.   \n",
       "216                  Virtue & Co.   \n",
       "218         Bradbury, Evans & Co.   \n",
       "472                 James Darling   \n",
       "480          Wertheim & Macintosh   \n",
       "\n",
       "                                                        Title     Author  \\\n",
       "Identifier                                                                 \n",
       "206                         Walter Forbes. [A novel.] By A. A      A. A.   \n",
       "216         All for Greed. [A novel. The dedication signed...  A., A. A.   \n",
       "218         Love the Avenger. By the author of “All for Gr...  A., A. A.   \n",
       "472         Welsh Sketches, chiefly ecclesiastical, to the...  A., E. S.   \n",
       "480         [The World in which I live, and my place in it...  A., E. S.   \n",
       "\n",
       "                                                   Flickr URL  \n",
       "Identifier                                                     \n",
       "206         http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "216         http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "218         http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "472         http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "480         http://www.flickr.com/photos/britishlibrary/ta...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.set_index('Identifier')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2206f2-f913-485c-8f45-0fa10c7d96dd",
   "metadata": {},
   "source": [
    "Notice that the leftmost column, which indicated the row number, is gone. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48042e7f-3e66-414a-8ef8-950c610404af",
   "metadata": {},
   "source": [
    "We can locate a specific record in the dataframe now using [loc[]](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html). Let's say we wanted to get the book with identifier 218. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7ae5d130-7339-4189-a157-406630d8957e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Place of Publication                                               London\n",
       "Date of Publication                                                  1869\n",
       "Publisher                                           Bradbury, Evans & Co.\n",
       "Title                   Love the Avenger. By the author of “All for Gr...\n",
       "Author                                                          A., A. A.\n",
       "Flickr URL              http://www.flickr.com/photos/britishlibrary/ta...\n",
       "Name: 218, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[218]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7584c7a-580c-4d4b-8897-fb64fb6f9f92",
   "metadata": {},
   "source": [
    "We can still find records by position using [iloc[]](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html). Python is generally 0-indexed, so our first record is referenced by 0, the 2nd is position 1, etc. So we can find the same record by doing accessing the 2 position (the third entry in the frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b2195861-3c38-46ba-9266-1628132ba8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Place of Publication                                               London\n",
       "Date of Publication                                                  1869\n",
       "Publisher                                           Bradbury, Evans & Co.\n",
       "Title                   Love the Avenger. By the author of “All for Gr...\n",
       "Author                                                          A., A. A.\n",
       "Flickr URL              http://www.flickr.com/photos/britishlibrary/ta...\n",
       "Name: 218, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71727e8-6b90-4337-b9d2-80370faa798e",
   "metadata": {},
   "source": [
    "Notice that we re-assigned the df variable ```df = df.set_index('Identifier')``` this is because by default, when we do an operation on a dataframe like .set_index() the operation returns a copy of the dataframe, and doesn't affect the original. If we want to bypass that, we can run the method in-place, telling Python that we want to set the index on the original dataframe. Then, we don't have to do re-assigning. ```df.set_index('Identifier', inplace=True)``` There will be times when you want to manipulate the dataframe directly and other times when you don't (for example when you just want to peek at what an operation will do, or you are still an intermediate stage of cleaning. You'll want to use [inplace=True carefully](https://www.askpython.com/python-modules/pandas/inplace-true-parameter). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a834190-e7e4-4056-8537-c5cb59af9fb1",
   "metadata": {},
   "source": [
    "## Tidying up Fields in the Data\n",
    "So far, we have removed unnecessary columns and changed the index of our DataFrame to something more sensible. In this section, we will clean specific columns and get them to a uniform format to get a better understanding of the dataset and enforce consistency. In particular, we will be cleaning Date of Publication and Place of Publication.\n",
    "\n",
    "Upon inspection, all of the data types are currently the <strong> object </strong> dtype, which in our case is roughly analogous to <strong> str </strong> in native Python. \n",
    "One field where it makes sense to enforce a numeric value is the date of publication so that we can do calculations down the road. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "18809cec-2782-4e9c-a78f-f7e8f5952d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identifier\n",
       "1905           1888\n",
       "1929    1839, 38-54\n",
       "2836           1897\n",
       "2854           1865\n",
       "2956        1860-63\n",
       "2957           1873\n",
       "3017           1866\n",
       "3131           1899\n",
       "4598           1814\n",
       "4884           1820\n",
       "Name: Date of Publication, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1905:, 'Date of Publication'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeca2b7-46d6-4116-8668-e738a8a4e1a4",
   "metadata": {},
   "source": [
    "A particular book can have only one date of publication. Therefore, we need to do the following:\n",
    "\n",
    "    - Remove the extra dates in square brackets, wherever present: 1879 [1878]\n",
    "    - Convert date ranges to their “start date”, wherever present: 1860-63; 1839, 38-54\n",
    "    - Completely remove the dates we are not certain about and replace them with NumPy’s NaN: [1897?]\n",
    "    - Convert the string nan to NumPy’s NaN value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b735cb98-ea20-4be7-a34f-f2fc8ced6670",
   "metadata": {},
   "source": [
    "We can use something called a [regular expression](https://www.w3schools.com/python/python_regex.asp) to extract the publication date for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9ad038c1-4ad7-4288-a49c-c03de2c3a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r'^(\\d{4})'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f29bee-8cc0-4283-9d1c-910caef6d64b",
   "metadata": {},
   "source": [
    "The regular expression above is meant to find any four digits at the beginning of a string, which suffices for our case. \n",
    "The above is a raw string (meaning that a backslash is no longer an escape character), which is standard practice with regular expressions.\n",
    "\n",
    "The \\d represents any digit, and {4} repeats this rule four times. \n",
    "The ^ character matches the start of a string, and the parentheses denote a capturing group, which signals to pandas that we want to extract that part of the regex. (We want ^ to avoid cases where [ starts off the string.)\n",
    "\n",
    "Let's see how this extraction pays off. We will use [str.extract()](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html) which allows us to extract strings that match our regex pattern in the Date of Publication column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "864f19b4-e0ab-478d-a0fd-3e370de76a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "extr = df['Date of Publication'].str.extract(r'^(\\d{4})', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f4f4b9d9-a01d-49a7-b388-5809a9598622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identifier\n",
       "206    1879\n",
       "216    1868\n",
       "218    1869\n",
       "472    1851\n",
       "480    1857\n",
       "Name: Date of Publication, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25395e78-86dd-4c80-b09f-92d78df2156c",
   "metadata": {},
   "source": [
    "Notice that the type for the date of publication is stiill dtype, meaning it is still basically a string. \n",
    "We can change the type for that column to a float by using [to_numeric()](https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5a9c47bb-5016-4389-806a-18cb78f01fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date of Publication'] = pd.to_numeric(extr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "32536632-5f0a-47e5-b9ee-eb5dd49fb612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date of Publication'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8389a4-9786-434d-931e-c82331d5be14",
   "metadata": {},
   "source": [
    "After our conversion to floats, we have inevitably lost some rows of data, as some don't dates\n",
    "conform to the date of publication standards (4 digits) we outlined in the regex. \n",
    "If we cared, we could look into why this is the case. We can calculate the number of rows in the dataframe that have a Null value for the date of publication like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4e437b59-b3f1-4403-a131-3dc8adbef9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11717147339205986"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date of Publication'].isnull().sum() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86422848-0b63-449c-96c3-d3870465ec39",
   "metadata": {},
   "source": [
    "So a little over 1 in 10 rows have no date of publication. A large part of the role of any data scientist or analyst\n",
    "is to clean the data. I challenge you to find "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78afe894-f27b-4da7-846b-7e15b27822eb",
   "metadata": {},
   "source": [
    "#### Challenge 1: Find out what the reason is for the null values for date of publication. The answer may be simple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2202c7-20a5-4011-ade7-af59a3b9ef0e",
   "metadata": {},
   "source": [
    "## Combining str Methods with NumPy to Clean Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a858998d-e891-4066-b47a-5fbc70582935",
   "metadata": {},
   "source": [
    "str.extract() that we used above was a [string operation](https://pandas.pydata.org/pandas-docs/stable/text.html),\n",
    "which is quick way to act on str-like objects that are in our dataframes. \n",
    "There are other str operations like \n",
    "[replace()](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html), [split()](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html), [capitalize()](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.capitalize.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce6bd1c-2f1f-45db-aa47-45da4a65ca8d",
   "metadata": {},
   "source": [
    "To clean the Place of Publication field, we can combine pandas str methods with NumPy’s [np.where](https://numpy.org/doc/stable/reference/generated/numpy.where.html) function. <br> This is where's general syntax:\n",
    "```np.where(condition, then, else)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d93f34-5d28-4a1e-a5f5-1461d1a713e8",
   "metadata": {},
   "source": [
    "Here, condition is either an array-like object or a Boolean mask. then is the value to be used if condition evaluates to True, and else is the value to be used otherwise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d16b6e6-5776-40be-953e-79076f86c370",
   "metadata": {},
   "source": [
    "Essentially, .where() takes each element in the object used for condition, checks whether that particular element evaluates to True in the context of the condition, and returns an ndarray containing then or else, depending on which applies. I will also note that where() can be nested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1bb452ee-5271-4ddc-9c6a-20c4cd1bf8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identifier\n",
       "206                                  London\n",
       "216                London; Virtue & Yorston\n",
       "218                                  London\n",
       "472                                  London\n",
       "480                                  London\n",
       "481                                  London\n",
       "519                                  London\n",
       "667     pp. 40. G. Bryan & Co: Oxford, 1898\n",
       "874                                 London]\n",
       "1143                                 London\n",
       "Name: Place of Publication, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Place of Publication'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5676f3b7-9dbb-4aae-93ff-4eb6634b6dfc",
   "metadata": {},
   "source": [
    "We see that for some rows, the place of publication is surrounded by other unnecessary information. \n",
    "If we were to look at more values, we would see that this is the case for only some rows \n",
    "that have their place of publication as <strong> ‘London’ </strong> or <strong> ‘Oxford’ </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eb75ef61-558d-4fda-9fd4-1fb15945acdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Place of Publication                                  Newcastle-upon-Tyne\n",
       "Date of Publication                                                1867.0\n",
       "Publisher                                                      T. Fordyce\n",
       "Title                   Local Records; or, Historical Register of rema...\n",
       "Author                      FORDYCE, T. - Printer, of Newcastle-upon-Tyne\n",
       "Flickr URL              http://www.flickr.com/photos/britishlibrary/ta...\n",
       "Name: 4157862, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[4157862]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fd6c0bec-19ed-4772-abbf-510fc224d669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Place of Publication                                  Newcastle upon Tyne\n",
       "Date of Publication                                                1834.0\n",
       "Publisher                                                Mackenzie & Dent\n",
       "Title                   An historical, topographical and descriptive v...\n",
       "Author                                              Mackenzie, E. (Eneas)\n",
       "Flickr URL              http://www.flickr.com/photos/britishlibrary/ta...\n",
       "Name: 4159587, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[4159587]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d46942-e8c1-4d20-90e2-0649484a95ce",
   "metadata": {},
   "source": [
    "You can see that these two entries have the same place of publication but in different formats. The first has dashes where there are supposed to be spaces. This is likely due to unconstrained data entry- there is no particular format that is required when they add a new book to the database. This is very common when dealing with data in the real world. You'll get stuff like this all the time. Another example: <br>\n",
    "Chicago, IL <br>\n",
    "Chicago <br>\n",
    "Chicago, Illinois <br>\n",
    "Addresses are particularly notorious for this sort of inconsistency, \n",
    "in fact there are whole essays and tools ([Ex 1](https://developers.google.com/maps/documentation/address-validation), [Ex 2](https://www.geocod.io/features/api/)) developed specifically about address validation for data analysis. \n",
    "Cleaning fields like this is the [grunt work](https://xkcd.com/1831/) of data analysts. We all hate it, but we must do it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9dac80-073e-47b3-b6f9-1ebf50036b6f",
   "metadata": {},
   "source": [
    "To clean this column in one sweep, we can use str.contains() to get a Boolean mask.\n",
    "We will do this to get the rows that contain the word London and Oxford. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5b82ed61-f0ac-4692-9ebd-36480e174147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identifier\n",
       "206    True\n",
       "216    True\n",
       "218    True\n",
       "472    True\n",
       "480    True\n",
       "Name: Place of Publication, dtype: bool"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub = df['Place of Publication']\n",
    "london = pub.str.contains('London')\n",
    "london[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ba2e9077-13ba-4712-83ec-0e38064de071",
   "metadata": {},
   "outputs": [],
   "source": [
    "oxford = pub.str.contains('Oxford')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "526d7dee-5fef-4430-9d8b-bf8fdef9ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Place of Publication'] = np.where(london, 'London',\n",
    "                                 np.where(oxford, 'Oxford',\n",
    "                                    pub.str.replace('-', ' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f268d9c-7985-45b1-a358-9dcc6c0693f8",
   "metadata": {},
   "source": [
    "Let's see that Newcastle line again after applying the cleaning. You'll notice the dashes are gone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3892be97-8b4d-4a76-abfd-773cf8a58636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Place of Publication                                  Newcastle upon Tyne\n",
       "Date of Publication                                                1867.0\n",
       "Publisher                                                      T. Fordyce\n",
       "Title                   Local Records; or, Historical Register of rema...\n",
       "Author                      FORDYCE, T. - Printer, of Newcastle-upon-Tyne\n",
       "Flickr URL              http://www.flickr.com/photos/britishlibrary/ta...\n",
       "Name: 4157862, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[4157862]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae280075-f3d3-4bc0-8ee2-fcb2c270a582",
   "metadata": {},
   "source": [
    "Let's break down what went on there. \n",
    "\n",
    "    london = pub.str.contains('London'): This line creates a boolean Series (london) that is True for entries in the 'Place of Publication' column containing the substring 'London' and False otherwise.\n",
    "\n",
    "    oxford = pub.str.contains('Oxford'): Similar to the previous line, this creates a boolean Series (oxford) for entries containing the substring 'Oxford'.\n",
    "\n",
    "    pub.str.replace('-', ' '): This part replaces all occurrences of hyphens ('-') in the 'Place of Publication' column with spaces. This operation is applied to the entire column.\n",
    "\n",
    "    np.where(london, 'London', ... ): This is a numpy function that takes three arguments:\n",
    "        The first argument (london) is a boolean condition (does our row have the word London in it?)\n",
    "        The second argument is the value to be assigned where the condition is True. In this case, it's the string 'London'.\n",
    "        The third argument is what happens where the condition is False. In this case, it's another np.where statement.\n",
    "\n",
    "    np.where(oxford, 'Oxford', pub.str.replace('-', ' ')): This is another np.where statement nested within the previous one. It follows the same logic:\n",
    "        If the 'oxford' condition is True (the row has the word Oxford in it) it assigns 'Oxford'.\n",
    "        If the 'oxford' condition is False, it goes to the next part, which is the replacement of hyphens with spaces.\n",
    "\n",
    "So, in summary, the code first checks if the entry contains 'London' and assigns 'London' if true. If false, it then checks if the entry contains 'Oxford' and assigns 'Oxford' if true. If neither condition is met, it replaces hyphens with spaces in the 'Place of Publication' column. This helps in cleaning up and standardizing the values in the column based on the specified conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c29877-dd26-4a2d-919b-cdf27c7d9330",
   "metadata": {},
   "source": [
    "We could of course use a different approach, for example clean up the London rows by themselves, then clean up the Oxford rows by themselves, and finally replace all dashes with spaces in any entries, this is particular technique just wraps it up for us nicely in one swoop. This is the power of <strong> NumPy </strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2059a11-a985-4d20-abab-50a0dc792fda",
   "metadata": {},
   "source": [
    "## Cleaning the Entire Dataset Using the map() Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd56db2-23eb-43e5-8dbf-6cda2f1ca8f9",
   "metadata": {},
   "source": [
    "Let's imagine that the dirty data isn't particularly localized to certain columns, like they were in our last example. \n",
    "Let's say I want to enforce certain standards across the entire dataset. We can do this using [map()](https://pandas.pydata.org/docs/dev/reference/api/pandas.DataFrame.map.html). \n",
    "Notice that in the tutorial applymap() is used. This has since been deprecated and replaced by map(), which is what we use in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f3d7f3-26c2-40cc-811c-9a4f63c0bffc",
   "metadata": {},
   "source": [
    "We will create a dataframe from the <b> university_towns.txt </b> file. \n",
    "If we take a peek at the file, you will notice it follows generally the format: <br>\n",
    "State[edit] <br>\n",
    "Region(University) <br>\n",
    "Region(University) <br>\n",
    "Region(University) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c59b8-284f-4335-b122-bcf7fa4ba149",
   "metadata": {},
   "source": [
    "$ head univerisity_towns.txt  <br>\n",
    "Alabama[edit]  <br>\n",
    "Auburn (Auburn University)[1] <br>\n",
    "Florence (University of North Alabama) <br>\n",
    "Jacksonville (Jacksonville State University)[2] <br>\n",
    "Livingston (University of West Alabama)[2] <br> \n",
    "Montevallo (University of Montevallo)[2] <br>\n",
    "Troy (Troy University)[2] <br>\n",
    "Tuscaloosa (University of Alabama, Stillman College, Shelton State)[3][4] <br>\n",
    "Tuskegee (Tuskegee University)[5] <br>\n",
    "Alaska[edit] <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c41c61-189d-4b02-9a4a-a3dc41ad85d8",
   "metadata": {},
   "source": [
    "We will use this formatting to our advantage to build a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e2b2945c-b497-4438-addb-66982a0588ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our university towns list\n",
    "university_towns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "878d544e-2b15-4723-86d2-3ced4a3feaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file, read each line, if it has edit in it, it is a state, otherwise it is a university town.\n",
    "with open('university_towns.txt') as file:\n",
    "    for line in file:\n",
    "        if '[edit]' in line:\n",
    "            # Remember this `state` until the next is found\n",
    "            state = line\n",
    "        else:\n",
    "            # Otherwise, we have a city; keep `state` as last-seen\n",
    "            university_towns.append((state, line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bd259797-30a5-4b68-a570-83c2102dba93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Alabama[edit]\\n', 'Auburn (Auburn University)[1]\\n'),\n",
       " ('Alabama[edit]\\n', 'Florence (University of North Alabama)\\n'),\n",
       " ('Alabama[edit]\\n', 'Jacksonville (Jacksonville State University)[2]\\n'),\n",
       " ('Alabama[edit]\\n', 'Livingston (University of West Alabama)[2]\\n'),\n",
       " ('Alabama[edit]\\n', 'Montevallo (University of Montevallo)[2]\\n')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at our constructed list\n",
    "university_towns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "456d68bb-41df-4f62-94fd-cb4170ac044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our list into a pandas dataframe with two columns\n",
    "towns_df = pd.DataFrame(university_towns,\n",
    "                         columns=['State', 'RegionName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3d553b36-1998-479a-893f-f05fc759747e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>RegionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama[edit]\\n</td>\n",
       "      <td>Auburn (Auburn University)[1]\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama[edit]\\n</td>\n",
       "      <td>Florence (University of North Alabama)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama[edit]\\n</td>\n",
       "      <td>Jacksonville (Jacksonville State University)[2]\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama[edit]\\n</td>\n",
       "      <td>Livingston (University of West Alabama)[2]\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama[edit]\\n</td>\n",
       "      <td>Montevallo (University of Montevallo)[2]\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             State                                         RegionName\n",
       "0  Alabama[edit]\\n                    Auburn (Auburn University)[1]\\n\n",
       "1  Alabama[edit]\\n           Florence (University of North Alabama)\\n\n",
       "2  Alabama[edit]\\n  Jacksonville (Jacksonville State University)[2]\\n\n",
       "3  Alabama[edit]\\n       Livingston (University of West Alabama)[2]\\n\n",
       "4  Alabama[edit]\\n         Montevallo (University of Montevallo)[2]\\n"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at our pandas dataframe\n",
    "towns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b985017-ec5b-4e18-a42c-00e35b8fd58e",
   "metadata": {},
   "source": [
    "We can now create a function we can call that we can apply to every element in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "940354df-d928-48c6-ac5f-c1d22c71b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citystate(item):\n",
    "    if ' (' in item:\n",
    "        return item[:item.find(' (')]\n",
    "    elif '[' in item:\n",
    "        return item[:item.find('[')]\n",
    "    else:\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adefed20-d918-4805-b90f-c3f40ce82e36",
   "metadata": {},
   "source": [
    "What does this method do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d622624-d19f-4a40-a64e-50585e4c89bc",
   "metadata": {},
   "source": [
    " 1.   if ' (' in item:: This condition checks if the string contains a substring ' ('. If it does, it means there is additional information enclosed in parentheses, possibly representing city and state information. If this condition is true, it executes the following:\n",
    "        return item[:item.find(' (')]: This extracts the substring of item from the beginning of the string (item[:) up to the index where the substring ' (' starts (item.find(' (')). It essentially <b> removes the information enclosed in parentheses and returns the remaining part of the string </b>\n",
    "\n",
    "2.    elif '[' in item:: If the first condition is false, this condition checks if the string contains a '[' character. If it does, it means there is additional information enclosed in square brackets. If this condition is true, it executes the following:\n",
    "        return item[:item.find('[')]: Similar to the previous case, it extracts the substring from the beginning of the string up to the index where the '[' character starts. <b> It removes the information enclosed in square brackets and returns the remaining part of the string. </b>\n",
    "\n",
    "3.    else:: If none of the above conditions are true, it means there are no parentheses or square brackets in the string. In this case, it simply returns the original string unchanged.\n",
    "\n",
    "In summary, this function is designed to clean up and extract city and state information from a string that might contain additional details enclosed in parentheses or square brackets. It returns the cleaned version of the string by removing the additional information if present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e66fd4b-9d4c-45a3-b641-659ee725caad",
   "metadata": {},
   "source": [
    "We can now apply this function to the entire dataframe using map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "60e1dc65-1352-48fd-bfdf-8c1df06cc394",
   "metadata": {},
   "outputs": [],
   "source": [
    "towns_df =  towns_df.map(get_citystate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a108a787-49fb-46d1-9d50-2d289835d651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>RegionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Auburn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Florence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Jacksonville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Livingston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Montevallo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State    RegionName\n",
       "0  Alabama        Auburn\n",
       "1  Alabama      Florence\n",
       "2  Alabama  Jacksonville\n",
       "3  Alabama    Livingston\n",
       "4  Alabama    Montevallo"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "towns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d62625-f0d6-4971-b51b-f8c707f3d59c",
   "metadata": {},
   "source": [
    "You may ask: Why wouldn't I always take this approach instead of using NumPy all the time? <br> The answer is <b>cost</b>. <br> If you have millions, billions, or even possibly trillions of rows of data, applying a map to the entire dataframe can be very time and resource expensive. It may be better to apply the filter to single columns of data at a time, especially with NumPy which is more efficient than pandas map() calls. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5f20d5-b53f-42b3-83bf-de24cd19f354",
   "metadata": {},
   "source": [
    "## Renaming Columns and Skipping Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740d682f-dcbe-465b-82c2-8b5bed4c17d0",
   "metadata": {},
   "source": [
    "Often, the datasets you’ll work with will have either column names that are not easy to understand, or unimportant information in the first few and/or last rows, such as definitions of the terms in the dataset, or footnotes.\n",
    "\n",
    "In that case, we’d want to rename columns and skip certain rows so that we can drill down to necessary information with correct and sensible labels.\n",
    "\n",
    "To demonstrate how we can go about doing this, let’s first take a glance at the initial five rows of the “olympics.csv” dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b186247-adbe-4221-9724-c7767087589a",
   "metadata": {},
   "source": [
    "$ head -n 5 Datasets/olympics.csv <br>\n",
    "0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15 <br>\n",
    ",? Summer,01 !,02 !,03 !,Total,? Winter,01 !,02 !,03 !,Total,? Games,01 !,02 !,03 !,Combined total <br>\n",
    "Afghanistan (AFG),13,0,0,2,2,0,0,0,0,0,13,0,0,2,2 <br>\n",
    "Algeria (ALG),12,5,2,8,15,3,0,0,0,0,15,5,2,8,15 <br>\n",
    "Argentina (ARG),23,18,24,28,70,18,0,0,0,0,41,18,24,28,70 <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bc5022-806c-4175-9185-45c0f9f9ecb3",
   "metadata": {},
   "source": [
    "Next we can read it into a dataframe and take a peek that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e3059841-e5f8-4cc9-8fe1-b1046992fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_df = pd.read_csv('olympics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "53022842-47a9-42ab-8de5-1c6112ec1611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>? Summer</td>\n",
       "      <td>01 !</td>\n",
       "      <td>02 !</td>\n",
       "      <td>03 !</td>\n",
       "      <td>Total</td>\n",
       "      <td>? Winter</td>\n",
       "      <td>01 !</td>\n",
       "      <td>02 !</td>\n",
       "      <td>03 !</td>\n",
       "      <td>Total</td>\n",
       "      <td>? Games</td>\n",
       "      <td>01 !</td>\n",
       "      <td>02 !</td>\n",
       "      <td>03 !</td>\n",
       "      <td>Combined total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan (AFG)</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria (ALG)</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina (ARG)</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Armenia (ARM)</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1     2     3     4      5         6     7     8  \\\n",
       "0                NaN  ? Summer  01 !  02 !  03 !  Total  ? Winter  01 !  02 !   \n",
       "1  Afghanistan (AFG)        13     0     0     2      2         0     0     0   \n",
       "2      Algeria (ALG)        12     5     2     8     15         3     0     0   \n",
       "3    Argentina (ARG)        23    18    24    28     70        18     0     0   \n",
       "4      Armenia (ARM)         5     1     2     9     12         6     0     0   \n",
       "\n",
       "      9     10       11    12    13    14              15  \n",
       "0  03 !  Total  ? Games  01 !  02 !  03 !  Combined total  \n",
       "1     0      0       13     0     0     2               2  \n",
       "2     0      0       15     5     2     8              15  \n",
       "3     0      0       41    18    24    28              70  \n",
       "4     0      0       11     1     2     9              12  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olympics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b122b4-7ea6-480c-a00e-0e61470f2e1a",
   "metadata": {},
   "source": [
    "The columns are the string form of integers indexed at 0. The row which should have been our header (i.e. the one to be used to set the column names) is at olympics_df.iloc[0]. This happened because our CSV file starts with 0, 1, 2, …, 15.\n",
    "\n",
    "Also, if we were to go to the [source](https://en.wikipedia.org/wiki/All-time_Olympic_Games_medal_table) of this dataset, we’d see that NaN above should really be something like “Country”, ? Summer is supposed to represent “Summer Games”, 01 ! should be “Gold”, and so on.\n",
    "\n",
    "Therefore, we need to do two things:\n",
    "\n",
    "    - Skip one row and set the header as the first (0-indexed) row\n",
    "    - Rename the columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39816a48-d5cf-4f8b-8eef-cc5584d416da",
   "metadata": {},
   "source": [
    "We can skip rows and set the header while reading the CSV file by passing some parameters to the read_csv() function. We can set the header to be the next line by setting header=1 in the [read_csv()](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c69f57b4-ace2-49df-a7dd-c6b255d894e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_df = pd.read_csv('olympics.csv', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "600f612e-53c6-433e-8b64-2d5bb8713d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>? Summer</th>\n",
       "      <th>01 !</th>\n",
       "      <th>02 !</th>\n",
       "      <th>03 !</th>\n",
       "      <th>Total</th>\n",
       "      <th>? Winter</th>\n",
       "      <th>01 !.1</th>\n",
       "      <th>02 !.1</th>\n",
       "      <th>03 !.1</th>\n",
       "      <th>Total.1</th>\n",
       "      <th>? Games</th>\n",
       "      <th>01 !.2</th>\n",
       "      <th>02 !.2</th>\n",
       "      <th>03 !.2</th>\n",
       "      <th>Combined total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan (AFG)</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Algeria (ALG)</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Argentina (ARG)</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armenia (ARM)</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australasia (ANZ) [ANZ]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Unnamed: 0  ? Summer  01 !  02 !  03 !  Total  ? Winter  \\\n",
       "0        Afghanistan (AFG)        13     0     0     2      2         0   \n",
       "1            Algeria (ALG)        12     5     2     8     15         3   \n",
       "2          Argentina (ARG)        23    18    24    28     70        18   \n",
       "3            Armenia (ARM)         5     1     2     9     12         6   \n",
       "4  Australasia (ANZ) [ANZ]         2     3     4     5     12         0   \n",
       "\n",
       "   01 !.1  02 !.1  03 !.1  Total.1  ? Games  01 !.2  02 !.2  03 !.2  \\\n",
       "0       0       0       0        0       13       0       0       2   \n",
       "1       0       0       0        0       15       5       2       8   \n",
       "2       0       0       0        0       41      18      24      28   \n",
       "3       0       0       0        0       11       1       2       9   \n",
       "4       0       0       0        0        2       3       4       5   \n",
       "\n",
       "   Combined total  \n",
       "0               2  \n",
       "1              15  \n",
       "2              70  \n",
       "3              12  \n",
       "4              12  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olympics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee555d51-534f-4c90-8f98-bdfb9a295f8b",
   "metadata": {},
   "source": [
    "We can rename the colummns to something more sensical using pandas' [rename()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html), which takes a mapping (a dictionary of old values:new values) and renames the columns accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c20b7d0d-867e-4d1e-9a6e-aef899735638",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names =  {'Unnamed: 0': 'Country',\n",
    "              '? Summer': 'Summer Olympics',\n",
    "              '01 !': 'Gold',\n",
    "              '02 !': 'Silver',\n",
    "              '03 !': 'Bronze',\n",
    "              '? Winter': 'Winter Olympics',\n",
    "              '01 !.1': 'Gold.1',\n",
    "              '02 !.1': 'Silver.1',\n",
    "              '03 !.1': 'Bronze.1',\n",
    "              '? Games': '# Games',\n",
    "              '01 !.2': 'Gold.2',\n",
    "              '02 !.2': 'Silver.2',\n",
    "              '03 !.2': 'Bronze.2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e8517bbe-a272-4dbe-8d37-7b5ad6decfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice in this case that I want to change the underlying dataframe, as the original headers are junk, so I use inplace=True\n",
    "olympics_df.rename(columns=new_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f8c748a9-bcaa-4276-b1dd-362e8998354a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Summer Olympics</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Silver</th>\n",
       "      <th>Bronze</th>\n",
       "      <th>Total</th>\n",
       "      <th>Winter Olympics</th>\n",
       "      <th>Gold.1</th>\n",
       "      <th>Silver.1</th>\n",
       "      <th>Bronze.1</th>\n",
       "      <th>Total.1</th>\n",
       "      <th># Games</th>\n",
       "      <th>Gold.2</th>\n",
       "      <th>Silver.2</th>\n",
       "      <th>Bronze.2</th>\n",
       "      <th>Combined total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan (AFG)</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Algeria (ALG)</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Argentina (ARG)</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armenia (ARM)</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australasia (ANZ) [ANZ]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Country  Summer Olympics  Gold  Silver  Bronze  Total  \\\n",
       "0        Afghanistan (AFG)               13     0       0       2      2   \n",
       "1            Algeria (ALG)               12     5       2       8     15   \n",
       "2          Argentina (ARG)               23    18      24      28     70   \n",
       "3            Armenia (ARM)                5     1       2       9     12   \n",
       "4  Australasia (ANZ) [ANZ]                2     3       4       5     12   \n",
       "\n",
       "   Winter Olympics  Gold.1  Silver.1  Bronze.1  Total.1  # Games  Gold.2  \\\n",
       "0                0       0         0         0        0       13       0   \n",
       "1                3       0         0         0        0       15       5   \n",
       "2               18       0         0         0        0       41      18   \n",
       "3                6       0         0         0        0       11       1   \n",
       "4                0       0         0         0        0        2       3   \n",
       "\n",
       "   Silver.2  Bronze.2  Combined total  \n",
       "0         0         2               2  \n",
       "1         2         8              15  \n",
       "2        24        28              70  \n",
       "3         2         9              12  \n",
       "4         4         5              12  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olympics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e115bafa-31c3-47e6-9dd5-f2b1b489af99",
   "metadata": {},
   "source": [
    "Great. We have gotten our dataframe to use the second row as the header, and cleaned up the column names using rename()!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d0c55-1a58-412a-8860-f71870b07b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
